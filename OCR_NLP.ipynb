{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10244951,"sourceType":"datasetVersion","datasetId":6336012},{"sourceId":10246440,"sourceType":"datasetVersion","datasetId":6337142},{"sourceId":10246576,"sourceType":"datasetVersion","datasetId":6337248}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\ndef preprocess_text(text):\n    if isinstance(text, list):  # 리스트일 경우 첫 번째 값 반환\n        text = text[0] if text else \"\"  # 리스트가 비어있으면 빈 문자열 반환\n    \n    if text is None:  # None 값 처리\n        return \"\"\n    \n    # 줄바꿈 제거 및 공백 정리\n    text = text.replace(\"\\n\", \" \").strip()\n    text = re.sub(r'\\s+', ' ', text)  # 중복 공백 제거\n    return text\n\n    '''\n    def time_converter(match):\n        period = match.group(1)  # 오전 또는 오후\n        hour = int(match.group(2))  # 시\n        minute = match.group(3) or \"00\"  # 분 (없으면 기본값 00)\n        \n\n        if period == \"오후\" and hour != 12:\n            hour += 12  # 오후는 12를 더함\n        elif period == \"오전\" and hour == 12:\n            hour = 0  # 오전 12시는 0시로 변환\n\n        return f\"{hour:02}:{minute}\"  # 24시간 형식으로 반환\n\n    text = re.sub(r\"(오전|오후)\\s*(\\d{1,2})시\\s*(\\d{1,2})?분?\", time_converter, text)\n    '''\n    \n\n\n\ndef extract_earliest(value, is_time=False):\n    if value is None or value.strip() == \"\":  # 빈 값 처리\n        return \"Null\"\n    \n    # 범위 구분자로 ~ 또는 - 처리\n    if any(separator in value for separator in [\"~\", \"-\"]):\n        for separator in [\"~\", \"-\"]:  # 모든 구분자에 대해 처리\n            if separator in value:\n                parts = value.split(separator)\n                parts = [p.strip() for p in parts if p.strip()]  # 공백 제거 및 빈 값 필터링\n                \n                if not parts:  # 모든 값이 빈 값인 경우\n                    return \"Null\"\n                \n                if is_time:\n                    try:\n                        return min(parts, key=lambda x: int(x.split(\":\")[0]) * 60 + int(x.split(\":\")[1]))\n                    except (IndexError, ValueError):\n                        return parts[0]  # 기본값으로 첫 번째 값 반환\n                else:\n                    return min(parts, key=lambda x: re.sub(r\"[^\\d]\", \"\", x))  # 숫자만 비교\n    return value\n\n\ndef preprocess_data(dataset):\n    for item in dataset:\n        # NoneType을 처리하기 위해 get 메서드 사용\n        item[\"original_text\"] = preprocess_text(item.get(\"original_text\", \"\"))\n        item[\"schedule_info\"][\"event_title\"] = preprocess_text(item[\"schedule_info\"].get(\"event_title\", \"\"))\n        item[\"schedule_info\"][\"date\"] = extract_earliest(preprocess_text(item[\"schedule_info\"].get(\"date\", \"\")))\n        item[\"schedule_info\"][\"time\"] = extract_earliest(preprocess_text(item[\"schedule_info\"].get(\"time\", \"Null\")), is_time=True)\n    return dataset\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T13:11:50.936775Z","iopub.execute_input":"2024-12-22T13:11:50.937064Z","iopub.status.idle":"2024-12-22T13:11:50.945432Z","shell.execute_reply.started":"2024-12-22T13:11:50.937041Z","shell.execute_reply":"2024-12-22T13:11:50.944622Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import json\n\n # 데이터셋 로드\ndef load_jsonl(file_path):\n    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n        return [json.loads(line) for line in f]\n    \ntrain_set= load_jsonl(\"/kaggle/input/dataset/filtered_train_set.jsonl\")\ntest_set = load_jsonl(\"/kaggle/input/dataset/filtered_test_set.jsonl\")\ntrain_data = preprocess_data(train_set)\ntest_data = preprocess_data(test_set)\n#print(train_data[:5])\ndef save_jsonl(data, file_path):\n    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n        for item in data:\n            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n\n# 파일 저장\nsave_jsonl(train_data, \"/kaggle/working/filtered_train_data.jsonl\")\nsave_jsonl(test_data, \"/kaggle/working/filtered_test_data.jsonl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T12:02:40.225140Z","iopub.execute_input":"2024-12-19T12:02:40.225457Z","iopub.status.idle":"2024-12-19T12:02:40.388970Z","shell.execute_reply.started":"2024-12-19T12:02:40.225432Z","shell.execute_reply":"2024-12-19T12:02:40.388270Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def augment_text_with_context(item):\n    text = item[\"original_text\"]\n    date = item[\"schedule_info\"].get(\"date\", \"Unknown Date\")\n    time = item[\"schedule_info\"].get(\"time\", \"Unknown Time\")\n    return f\"{text} [Date: {date}] [Time: {time}]\"\n\nfor item in train_data:\n    item[\"original_text\"] = augment_text_with_context(item)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T11:39:23.037166Z","iopub.execute_input":"2024-12-19T11:39:23.037503Z","iopub.status.idle":"2024-12-19T11:39:23.043187Z","shell.execute_reply.started":"2024-12-19T11:39:23.037471Z","shell.execute_reply":"2024-12-19T11:39:23.042274Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import logging\n\nimport os\nimport torch\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader, RandomSampler\nfrom transformers import AdamW\nimport random\nimport numpy as np\n\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n# fine-tunning 이전 코드\n'''\ndef read_data(file_path):\n    import json\n    datas = []\n    with open(file_path, \"r\", encoding=\"utf8\") as infile:\n        for line in infile:\n            item = json.loads(line)\n            text = item[\"original_text\"]\n            title = item[\"schedule_info\"][\"event_title\"]\n            datas.append((text, title))\n    return datas\n\n\ndef convert_data2feature(datas, max_length, max_dec_length, tokenizer):\n    input_ids_features, attention_mask_features, decoder_input_features, decoder_attention_mask_features, label_features = [], [], [], [], []\n\n    for text, title in tqdm(datas, desc=\"convert_data2feature\"):\n        # tokenizer를 사용하여 입력 문장을 word piece 단위로 분리\n        tokenized_text = tokenizer.tokenize(text)\n        tokenized_title= tokenizer.tokenize(title)\n        #########################################\n        # 인코더는 출력 없음\n        input_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n        attention_mask = [1]*len(input_ids)\n\n        # 디코더의 입력:  start 심볼 + 본문 출력 : 본문 + end 심볼\n        decoder_input = tokenizer.convert_tokens_to_ids(['<s>'] + tokenized_title)\n        decoder_attention_mask = [1] *len(decoder_input)\n        label = tokenizer.convert_tokens_to_ids(tokenized_title + ['</s>'])\n\n        padding = [tokenizer.convert_tokens_to_ids(tokenizer.pad_token)] * (max_length - len(input_ids))\n        input_ids += padding\n        attention_mask += padding\n\n        ### decoder padding\n        decoder_padding = [tokenizer.convert_tokens_to_ids(tokenizer.pad_token)] * (max_dec_length - len(decoder_input))\n        decoder_input += decoder_padding\n        decoder_attention_mask += decoder_padding\n        label += decoder_padding\n\n        #########################################\n\n        # 변환한 데이터를 각 리스트에 저장\n        input_ids_features.append(input_ids[:max_length])\n        attention_mask_features.append(attention_mask[:max_length])\n        decoder_input_features.append(decoder_input[:max_dec_length])\n        decoder_attention_mask_features.append(decoder_attention_mask[:max_length])\n        label_features.append(label[:max_dec_length])\n\n    # 변환한 데이터를 Tensor 객체에 담아 반환\n    input_ids_features = torch.tensor(input_ids_features, dtype=torch.long)\n    attention_mask_features = torch.tensor(attention_mask_features, dtype=torch.long)\n    decoder_input_features = torch.tensor(decoder_input_features, dtype=torch.long)\n    decoder_attention_mask_features = torch.tensor(decoder_attention_mask_features, dtype=torch.long)\n    label_features = torch.tensor(label_features, dtype=torch.long)\n\n    return input_ids_features, attention_mask_features, decoder_input_features, decoder_attention_mask_features, label_features\n'''\n# fine -tunning 코드\ndef read_data(file_path):\n    import json\n    datas = []\n    with open(file_path, \"r\", encoding=\"utf8\") as infile:\n        for line in infile:\n            item = json.loads(line)\n            text = item[\"original_text\"]\n            title = item[\"schedule_info\"][\"event_title\"]\n            \n            # `date`와 `time`을 데이터셋에서 가져오기\n            date = item[\"schedule_info\"].get(\"date\", \"\")\n            time = item[\"schedule_info\"].get(\"time\", \"\")\n            \n            datas.append((text, title, date, time))\n    return datas\ndef convert_data2feature(datas, max_length, max_dec_length, tokenizer, boost_weight=2.0):\n    input_ids_features, attention_mask_features, decoder_input_features, decoder_attention_mask_features, label_features, importance_masks = [], [], [], [], [], []\n\n    for text, title, date, time in tqdm(datas, desc=\"convert_data2feature\"):\n        # Tokenize 텍스트 및 타이틀\n        tokenized_text = tokenizer.tokenize(text)\n        tokenized_title = tokenizer.tokenize(title)\n\n        # Tokenize date와 time\n        tokenized_date = tokenizer.tokenize(date)\n        tokenized_time = tokenizer.tokenize(time)\n\n        #########################################\n        # 인코더 입력 데이터 준비\n        input_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n        attention_mask = [1] * len(input_ids)\n\n        # 디코더 입력 준비\n        decoder_input = tokenizer.convert_tokens_to_ids(['<s>'] + tokenized_title)\n        decoder_attention_mask = [1] * len(decoder_input)\n        label = tokenizer.convert_tokens_to_ids(tokenized_title + ['</s>'])\n\n        # 중요도 마스크 생성: date와 time 토큰에 가중치 적용\n        importance_mask = [\n            boost_weight if token in tokenized_date or token in tokenized_time else 1.0\n            for token in tokenized_text\n        ]\n\n        # Padding 처리\n        padding = [tokenizer.pad_token_id] * (max_length - len(input_ids))\n        input_ids += padding\n        attention_mask += [0] * len(padding)\n        importance_mask += [1.0] * len(padding)  # 패딩 토큰은 기본 가중치\n\n        decoder_padding = [tokenizer.pad_token_id] * (max_dec_length - len(decoder_input))\n        decoder_input += decoder_padding\n        decoder_attention_mask += decoder_padding\n        label += decoder_padding\n\n        #########################################\n\n        # 변환한 데이터를 각 리스트에 저장\n        input_ids_features.append(input_ids[:max_length])\n        attention_mask_features.append(attention_mask[:max_length])\n        decoder_input_features.append(decoder_input[:max_dec_length])\n        decoder_attention_mask_features.append(decoder_attention_mask[:max_dec_length])\n        label_features.append(label[:max_dec_length])\n        importance_masks.append(importance_mask[:max_length])\n\n    # 텐서 변환\n    input_ids_features = torch.tensor(input_ids_features, dtype=torch.long)\n    attention_mask_features = torch.tensor(attention_mask_features, dtype=torch.long)\n    decoder_input_features = torch.tensor(decoder_input_features, dtype=torch.long)\n    decoder_attention_mask_features = torch.tensor(decoder_attention_mask_features, dtype=torch.long)\n    label_features = torch.tensor(label_features, dtype=torch.long)\n    importance_masks = torch.tensor(importance_masks, dtype=torch.float)\n\n    return (input_ids_features, attention_mask_features, decoder_input_features, decoder_attention_mask_features, label_features, importance_masks)\n\n\ndef to_list(tensor):\n    return tensor.detach().cpu().tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T15:38:32.509148Z","iopub.execute_input":"2024-12-19T15:38:32.509457Z","iopub.status.idle":"2024-12-19T15:38:32.520944Z","shell.execute_reply.started":"2024-12-19T15:38:32.509432Z","shell.execute_reply":"2024-12-19T15:38:32.520091Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"\nlogger = logging.getLogger(__name__)\n\nfrom torch.utils.data import (DataLoader, TensorDataset, RandomSampler, SequentialSampler)\nfrom transformers import BartForConditionalGeneration\nfrom transformers import PreTrainedTokenizerFast\nfrom transformers import BartTokenizer\nfrom sklearn.metrics import accuracy_score\n\n# 학습\ndef train(config):\n    tokenizer = PreTrainedTokenizerFast.from_pretrained(config[\"pretrained_model_name_or_path\"])\n    model = BartForConditionalGeneration.from_pretrained(config[\"pretrained_model_name_or_path\"]).cuda()\n\n    # 데이터 읽기\n    train_datas = read_data(config[\"train_data_path\"])\n    test_datas = read_data(config[\"test_data_path\"])\n\n    # 데이터 전처리\n    train_features = convert_data2feature(train_datas, config[\"max_length\"], config[\"max_dec_length\"], tokenizer)\n    test_features = convert_data2feature(test_datas, config[\"max_length\"], config[\"max_dec_length\"], tokenizer)\n\n    # DataLoader 생성\n    train_dataloader = DataLoader(\n        TensorDataset(*train_features),\n        sampler=RandomSampler(TensorDataset(*train_features)),\n        batch_size=config[\"batch_size\"]\n    )\n    test_dataloader = DataLoader(\n        TensorDataset(*test_features),\n        sampler=SequentialSampler(TensorDataset(*test_features)),\n        batch_size=config[\"batch_size\"]\n    )\n\n    # Optimizer 설정\n    optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n    #optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n    global_step = 1\n    model.zero_grad()\n    set_seed(config[\"seed\"])\n\n    for epoch in range(config[\"epoch\"]):\n        for step, batch in enumerate(train_dataloader):\n            model.train()\n            batch = tuple(t.cuda() for t in batch)\n\n            outputs = model(\n                input_ids=batch[0],\n                attention_mask=batch[1],\n                decoder_input_ids=batch[2],\n                decoder_attention_mask=batch[3],\n                labels=batch[4],\n                return_dict=True\n            )\n\n            # 가중치 적용\n            loss = outputs.loss\n            importance_mask = batch[5]\n            weighted_loss = (loss * importance_mask).mean()\n\n            weighted_loss.backward()\n            optimizer.step()\n            model.zero_grad()\n            global_step += 1\n\n            if (global_step + 1) % 50 == 0:\n                print(f\"Step {global_step + 1}, Loss: {weighted_loss.item()}\")\n\n            if global_step % 500 == 0:\n                evaluate(config, model, tokenizer, test_dataloader)\n                output_dir = os.path.join(config[\"output_dir_path\"], f\"checkpoint-{global_step}\")\n                if not os.path.exists(output_dir):\n                    os.makedirs(output_dir)\n                model.save_pretrained(output_dir)\n\n    return global_step, weighted_loss.item()\n\n# 평가\ndef evaluate(config, model, tokenizer, test_dataloader):\n    model.eval()\n    total_correct, total_samples = 0, 0\n    all_refs, all_preds = [], []\n\n    for batch in tqdm(test_dataloader):\n        batch = tuple(t.cuda() for t in batch)\n        dec_outputs = model.generate(\n            input_ids=batch[0],\n            attention_mask=batch[1],\n            max_length=config[\"max_dec_length\"],\n            eos_token_id=1,\n            do_sample=False,\n        )\n\n        batch_size = batch[0].size(0)\n        dec_outputs = dec_outputs.tolist()\n        dec_labels = batch[4].tolist()\n\n        for i in range(batch_size):\n            pred = \"\".join(tokenizer.convert_ids_to_tokens(dec_outputs[i][1:])).replace(\"<pad>\", \"\").replace(\"</s>\", \"\")\n            ref = \"\".join(tokenizer.convert_ids_to_tokens(dec_labels[i][:-1])).replace(\"<pad>\", \"\").replace(\"</s>\", \"\")\n            all_refs.append(ref)\n            all_preds.append(pred)\n            total_correct += int(pred == ref)\n            total_samples += 1\n\n    accuracy = total_correct / total_samples if total_samples > 0 else 0\n    print(f\"Accuracy: {accuracy * 100:.2f}% ({total_correct}/{total_samples})\")\n    sklearn_accuracy = accuracy_score(all_refs, all_preds)\n    print(f\"Sklearn Accuracy: {sklearn_accuracy * 100:.2f}%\")\n\n\n ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T15:51:09.840897Z","iopub.execute_input":"2024-12-19T15:51:09.841229Z","iopub.status.idle":"2024-12-19T15:51:09.853565Z","shell.execute_reply.started":"2024-12-19T15:51:09.841200Z","shell.execute_reply":"2024-12-19T15:51:09.852730Z"}},"outputs":[],"execution_count":97},{"cell_type":"markdown","source":"fine tunning 이전 코드\n","metadata":{}},{"cell_type":"code","source":"'''\nlogger = logging.getLogger(__name__)\n\nfrom torch.utils.data import (DataLoader, TensorDataset, RandomSampler, SequentialSampler)\nfrom transformers import BartForConditionalGeneration\nfrom transformers import PreTrainedTokenizerFast\nfrom transformers import BartTokenizer\nfrom sklearn.metrics import accuracy_score\n\ndef train(config):\n    tokenizer = PreTrainedTokenizerFast.from_pretrained(config[\"pretrained_model_name_or_path\"])\n    model = BartForConditionalGeneration.from_pretrained(config[\"pretrained_model_name_or_path\"]).cuda()\n\n    #tokenizer = BartTokenizer.from_pretrained(config[\"pretrained_model_name_or_path\"])\n    #model = BartForConditionalGeneration.from_pretrained(config[\"pretrained_model_name_or_path\"]).cuda()\n\n    \"\"\" Train the model \"\"\"\n    # 학습 및 평가 데이터 읽기\n    train_datas = read_data(config[\"train_data_path\"])\n    test_datas = read_data(config[\"test_data_path\"])\n\n    # 입력 데이터 전처리\n    train_input_ids_features, train_attention_mask_features, train_decoder_input_features, train_decoder_attention_mask_features, train_label_features = \\\n        convert_data2feature(train_datas, config[\"max_length\"],config[\"max_dec_length\"], tokenizer)\n    test_input_ids_features, test_attention_mask_features, test_decoder_input_features, test_decoder_attention_mask_features, test_label_features = \\\n        convert_data2feature(test_datas, config[\"max_length\"], config[\"max_dec_length\"], tokenizer)\n\n    # 학습 데이터를 batch 단위로 추출하기 위한 DataLoader 객체 생성\n    train_features = TensorDataset(train_input_ids_features, train_attention_mask_features, train_decoder_input_features, train_decoder_attention_mask_features, train_label_features)\n    train_dataloader = DataLoader(train_features, sampler=RandomSampler(train_features),\n                                  batch_size=config[\"batch_size\"])\n\n    # 평가 데이터를 batch 단위로 추출하기 위한 DataLoader 객체 생성\n    test_features = TensorDataset(test_input_ids_features, test_attention_mask_features, test_decoder_input_features, test_decoder_attention_mask_features, test_label_features)\n    test_dataloader = DataLoader(test_features, sampler=SequentialSampler(test_features),\n                                 batch_size=config[\"batch_size\"])\n\n    # 모델 학습을 위한 optimizer\n    optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n    global_step = 1\n\n    tr_loss, logging_loss = 0.0, 0.0\n    model.zero_grad()\n\n    set_seed(config[\"seed\"])\n\n    for epoch in range(config[\"epoch\"]):\n        for step, batch in enumerate(train_dataloader):\n            # Skip past any already trained steps if resuming training\n            model.train()\n            batch = tuple(t.cuda() for t in batch)\n            outputs = model(input_ids=batch[0],\n                              attention_mask=batch[1],\n                              decoder_input_ids=batch[2],\n                              decoder_attention_mask=batch[3],\n                              labels=batch[4],\n                                return_dict=True)\n\n            loss = outputs[\"loss\"]\n\n            loss.backward()\n            if (global_step+1) % 50 == 0:\n                print(\"{} Processed.. Total Loss : {}\".format(global_step+1, loss.item()))\n\n            tr_loss += loss.item()\n\n            optimizer.step()\n            model.zero_grad()\n            global_step += 1\n\n            # Save model checkpoint\n            if global_step % 500 == 0:\n                #평가\n                evaluate(config, model, tokenizer, test_dataloader)\n                output_dir = os.path.join(config[\"output_dir_path\"], \"checkpoint-{}\".format(global_step))\n                print(\"Model Save in {}\".format(output_dir))\n                if not os.path.exists(output_dir):\n                    os.makedirs(output_dir)\n\n                # Take care of distributed/parallel training\n                model_to_save = model.module if hasattr(model, \"module\") else model\n                model_to_save.save_pretrained(output_dir)\n\n    return global_step, tr_loss / global_step\n\ndef evaluate(config, model, tokenizer, test_dataloader):\n    model.eval()\n    total_correct = 0\n    total_samples = 0\n    all_refs = []\n    all_preds = []\n    for batch in tqdm(test_dataloader):\n        batch = tuple(t.cuda() for t in batch)\n\n        dec_outputs = model.generate(input_ids = batch[0],\n                                     attention_mask=batch[1],\n                                     max_length=config[\"max_dec_length\"],\n                                     eos_token_id=1,\n                                     do_sample=False,\n                                     bad_words_ids=[[5]]\n                                    )\n\n        batch_size = batch[0].size()[0]\n\n        dec_outputs = dec_outputs.tolist()\n        dec_labels = batch[4].tolist()\n\n        for index in range(batch_size):\n            if 1 in dec_outputs[index]:\n                dec_outputs[index] = dec_outputs[index]\n            if -100 in dec_labels[index]:\n                dec_labels[index] = dec_labels[index][:dec_labels[index].index(-100)]\n            pred = \"\".join(tokenizer.convert_ids_to_tokens(dec_outputs[index][1:])).replace(\"Ġ\", \" \").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").replace(\"▁\", \" \")\n            ref = \"\".join(tokenizer.convert_ids_to_tokens(dec_labels[index][:-1])).replace(\"Ġ\", \" \").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").replace(\"▁\", \" \")\n            all_refs.append(ref)\n            all_preds.append(pred)\n\n            if pred == ref:\n                total_correct += 1\n            total_samples += 1\n\n            #print(\"Correct : {}\\nPredict  : {}\\n\".format(ref, pred))\n     # Calculate accuracy\n    accuracy = total_correct / total_samples if total_samples > 0 else 0\n    print(\"\\nAccuracy: {:.2f}% ({}/{})\".format(accuracy * 100, total_correct, total_samples))\n\n    # Optionally: Use sklearn's accuracy_score for further validation\n    sklearn_accuracy = accuracy_score(all_refs, all_preds)\n    print(\"Sklearn Accuracy: {:.2f}%\".format(sklearn_accuracy * 100))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T13:07:04.056216Z","iopub.execute_input":"2024-12-19T13:07:04.056786Z","iopub.status.idle":"2024-12-19T13:07:04.070571Z","shell.execute_reply.started":"2024-12-19T13:07:04.056754Z","shell.execute_reply":"2024-12-19T13:07:04.069621Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"학습 실행","metadata":{}},{"cell_type":"code","source":"root_dir = \"/kaggle/working/\"\nif (__name__ == \"__main__\"):\n    save_dir = os.path.join(root_dir, \"save\")\n    output_dir = os.path.join(root_dir, \"output\")\n    cache_dir = os.path.join(root_dir, \"cache\")\n\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    if not os.path.exists(save_dir):\n        os.makedirs(save_dir)\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    set_seed(seed=1234)\n\n    config = {\"mode\": \"train\",\n              \"train_data_path\": \"/kaggle/working/filtered_test_data.jsonl\",\n              \"test_data_path\": \"/kaggle/working/filtered_test_data.jsonl\",\n              \"output_dir_path\": output_dir,\n              \"save_dir_path\": save_dir,\n              \"cache_dir_path\": cache_dir,\n              \"pretrained_model_name_or_path\": \"hyunwoongko/kobart\",\n              \"max_length\": 512,\n              \"max_dec_length\": 60,\n              \"epoch\": 30,\n              \"batch_size\": 16,\n              \"seed\": 42,\n              }\n\n    if (config[\"mode\"] == \"train\"):\n        train(config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T15:51:15.937915Z","iopub.execute_input":"2024-12-19T15:51:15.938291Z","iopub.status.idle":"2024-12-19T16:00:38.007248Z","shell.execute_reply.started":"2024-12-19T15:51:15.938258Z","shell.execute_reply":"2024-12-19T16:00:38.006595Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nYou passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\nconvert_data2feature: 100%|██████████| 263/263 [00:00<00:00, 1067.14it/s]\nconvert_data2feature: 100%|██████████| 263/263 [00:00<00:00, 1198.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Step 50, Loss: 5.016598151996732e-05\nStep 100, Loss: 1.0974742508551572e-05\nStep 150, Loss: 6.810571903770324e-06\nStep 200, Loss: 4.172928129264619e-06\nStep 250, Loss: 3.4979943848156836e-06\nStep 300, Loss: 5.864443210157333e-06\nStep 350, Loss: 1.2459269100872916e-06\nStep 400, Loss: 2.2050262487027794e-06\nStep 450, Loss: 7.236949386424385e-07\nStep 500, Loss: 1.5641962818335742e-06\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 17/17 [00:08<00:00,  1.90it/s]\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 1}\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 98.48% (259/263)\nSklearn Accuracy: 98.48%\n","output_type":"stream"}],"execution_count":98},{"cell_type":"code","source":"import base64\nimport requests\nimport re\ndef preprocess_text(text):\n    if isinstance(text, list):  # 리스트일 경우 첫 번째 값 반환\n        text = text[0] if text else \"\"  # 리스트가 비어있으면 빈 문자열 반환\n    \n    if text is None:  # None 값 처리\n        return \"\"\n    \n    # 줄바꿈 제거 및 공백 정리\n    text = text.replace(\"\\n\", \" \").strip()\n    text = re.sub(r'\\s+', ' ', text)  # 중복 공백 제거\n    return text\ndef extract_text_from_image_google_vision(image_path, api_key):\n    url = f\"https://vision.googleapis.com/v1/images:annotate?key={api_key}\"\n\n    with open(image_path, \"rb\") as image_file:\n        image_content = base64.b64encode(image_file.read()).decode('utf-8')\n\n    # 요청 페이로드 생성\n    payload = {\n        \"requests\": [\n            {\n                \"image\": {\"content\": image_content},  \n                \"features\": [{\"type\": \"TEXT_DETECTION\"}]\n            }\n        ]\n    }\n\n    headers = {\"Content-Type\": \"application/json\"}\n\n    # Google Vision API 호출\n    response = requests.post(url, headers=headers, json=payload)\n    \n    if response.status_code == 200:\n        result = response.json()\n        try:\n            # 텍스트만 추출\n            texts = result[\"responses\"][0][\"textAnnotations\"]\n            return texts[0][\"description\"].strip() if texts else \"\"\n        except Exception as e:\n            print(\"결과 파싱 중 오류:\", e)\n            return \"\"\n    else:\n        print(\"API 호출 오류:\", response.status_code, response.text)\n        return \"\"\n\n'''\ndef extract_schedule_with_gemini(api_key, text):\n    url = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent\"\n    headers = {\"Content-Type\": \"application/json\"}\n    \n    # Prompt 생성\n    prompt = f\"\"\"\n    아래 텍스트를 분석하여 일정에 기록할 수 있도록 일정 제목, 날짜, 시간과 같은 일정 정보를 JSON 형식으로 추출해주세요.\n    반환되는 날짜는 반드시 \"YYYY.MM.DD\" 형식으로, 시간은 \"HH:MM\" (24시간제) 형식으로 통일해주세요.\n    만약 날짜나 시간 정보가 명확하지 않다면, 해당 필드는 \"Null\"로 설정해주세요.\n    여러 날짜와 시간이 나타난다면, 가장 이른 날짜와 시간을 기준으로 표시해주세요.\n\n    텍스트: {text}\n\n    JSON 형식 예시:\n    {{\n      \"original_text\": \"전체 텍스트\",\n      \"schedule_info\": {{\n        \"event_title\": \"이벤트 제목\",\n        \"date\": \"2024-12-25\",\n        \"time\": \"14:00\"\n      }}\n    }}\n    \"\"\"\n\n    # 요청 페이로드 생성\n    payload = {\n        \"contents\": [{\"parts\": [{\"text\": prompt}]}]\n    }\n    # API 호출\n    response = requests.post(url, headers=headers, json=payload, params={\"key\": api_key})\n    \n    if response.status_code == 200:\n        try:\n            response_text = response.json()[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n            #return json.loads(response_text) \n            # JSON 형식으로 파싱\n            return response_text\n        except Exception as e:\n            print(\"결과 파싱 중 오류 발생:\", e)\n            return None\n    else:\n        print(\"API 호출 오류:\", response.status_code, response.text)\n        return None\n'''\ngemini_api_key = \"AIzaSyCEtG0v1gxLCykmxscNwFat0rgeWb990NA\" \ntext = extract_text_from_image_google_vision(\"/kaggle/input/image2/2024-12-19  10.39.46.png\",  gemini_api_key)\ntext = preprocess_text(text)\n#answer = extract_schedule_with_gemini( gemini_api_key, text)\n#print(answer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T13:30:05.544556Z","iopub.execute_input":"2024-12-22T13:30:05.544884Z","iopub.status.idle":"2024-12-22T13:30:05.552814Z","shell.execute_reply.started":"2024-12-22T13:30:05.544859Z","shell.execute_reply":"2024-12-22T13:30:05.552000Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"train Model로 title 추출","metadata":{}},{"cell_type":"code","source":"def generate_title_from_text(model, tokenizer, text, max_length, max_dec_length):\n    \"\"\"본문에서 제목 생성\"\"\"\n    model.eval()\n\n    # 입력 텍스트를 토큰화 및 Tensor 변환\n    inputs = tokenizer(\n        text, \n        return_tensors=\"pt\", \n        max_length=max_length, \n        truncation=True, \n        padding=\"max_length\"\n    )\n\n    input_ids = inputs['input_ids'].cuda()\n    attention_mask = inputs['attention_mask'].cuda()\n\n    # 모델을 사용해 제목 생성\n    with torch.no_grad():\n        generated_ids = model.generate(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            max_length=max_dec_length,\n            eos_token_id=tokenizer.eos_token_id,\n            do_sample=False\n        )\n\n    # 생성된 제목 디코딩\n    title = tokenizer.decode(\n        generated_ids[0], \n        skip_special_tokens=True, \n        clean_up_tokenization_spaces=True\n    )\n    return title\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T13:33:08.535387Z","iopub.execute_input":"2024-12-19T13:33:08.535721Z","iopub.status.idle":"2024-12-19T13:33:08.541016Z","shell.execute_reply.started":"2024-12-19T13:33:08.535697Z","shell.execute_reply":"2024-12-19T13:33:08.540034Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"#test\nif __name__ == \"__main__\":\n    # 모델 및 토크나이저 로드\n    model_path = \"/kaggle/working/output/checkpoint-500\"\n    tokenizer_path = \"hyunwoongko/kobart\"\n    model = BartForConditionalGeneration.from_pretrained(model_path).cuda()\n    tokenizer = PreTrainedTokenizerFast.from_pretrained(tokenizer_path)\n\n    # 이미지 경로\n    print(\"Extracted Text:\\n\",text)\n\n    # 학습된 모델로 제목 생성\n    max_length = 250\n    max_dec_length = 60\n    generated_title = generate_title_from_text(model, tokenizer,text, max_length, max_dec_length)\n    print(\"Generated Title:\\n\", generated_title)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T13:45:18.205908Z","iopub.execute_input":"2024-12-19T13:45:18.206194Z","iopub.status.idle":"2024-12-19T13:45:19.032347Z","shell.execute_reply.started":"2024-12-19T13:45:18.206172Z","shell.execute_reply":"2024-12-19T13:45:19.031582Z"}},"outputs":[{"name":"stderr","text":"You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n","output_type":"stream"},{"name":"stdout","text":"Extracted Text:\n ITL Meet Up 2: 전체 타임라인 공개 12월 20일 (금) 진행될 TL Meet Up 2의 전체 타임라인을 공개합니다! 아래 안내 사항을 꼭 숙지하셔서 원활하게 행사에 참여하시길 바랍니다 입장 시간은 파트별 상이합니다. [1부]20시-20시 45분 (디자인 / 서버) 쉬는 시간: 20시 45분 - 21시 [2부]21시-21시 45분(PM/ 안드로이드 / iOS/웹) 쉬는시간 : 21시 45분 - 22시 [3부] 22시-22시 45분 (파트 무관 자유 네트워킹) 퇴장 시간: 22시 45분 - 23시 --- OTL 후보분들은 19시 30분(30분 전)까지 ZEP에 입장해주세요. PM/안드로이드/iOS/웹 참여자분들은 19시 50분(10분 전)까지 ZEP에 입장해주세요. 디자인/서버 참여자분들은 20시 50분(10분 전)까지 ZEP에 입장해주세요. 밋업이 시작되면 각 파트장님 인솔에 따라 이동해... 화할 때 주의가 필요한 방입니다. 잠금 ㅎ\nGenerated Title:\n ITL Meet Up 2: 전체 타임라인 공개\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"Pipeline을 통한 NER과정 수행","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\nfrom dateutil.parser import parse\nimport re\n\nimport torch\n\n# GPU 사용 가능 여부 확인\ndevice = 0 if torch.cuda.is_available() else -1\n\nner_model = pipeline(\n    \"token-classification\",\n    model=\"monologg/koelectra-small-finetuned-naver-ner\",\n    tokenizer=\"monologg/koelectra-small-finetuned-naver-ner\",\n    device=device)\n\ndef extract_datetime_entities(text):\n    \"\"\"NER을 통해 텍스트에서 날짜 및 시간을 추출\"\"\"\n    # NER 결과\n    ner_results = ner_model(text)\n    #print(ner_results)\n\n    # 날짜 및 시간 엔티티만 필터링\n    date_entities = [res[\"word\"] for res in ner_results if \"DAT\" in res[\"entity\"]]\n    time_entities = [res[\"word\"] for res in ner_results if \"TIM\" in res[\"entity\"]]\n    print(date_entities)\n    print(time_entities)    \n    # 정규화\n    normalized_times = normalize_times(time_entities)\n    normalized_dates = date_entities\n\n    return normalized_dates,normalized_times\n\n\n  '''normalized_dates = []\n    for entity in date_entities:\n        try:\n            # 날짜/시간 정규화\n            normalized_date = parse(entity, fuzzy=True)\n            normalized_dates.append(normalized_date)\n        except Exception:\n            pass  # 정규화 실패시 무시\n            '''\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T14:44:16.889116Z","iopub.execute_input":"2024-12-19T14:44:16.889398Z","iopub.status.idle":"2024-12-19T14:44:17.074804Z","shell.execute_reply.started":"2024-12-19T14:44:16.889377Z","shell.execute_reply":"2024-12-19T14:44:17.074140Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"def get_earliest_date(dates):\n    \"\"\"가장 빠른 날짜/시간 반환\"\"\"\n    if not dates:\n        return None\n    return min(dates)\ndef get_earliest_time(times):\n    \"\"\"가장 빠른 날짜/시간 반환\"\"\"\n    if not times:\n        return None\n    return min(times)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T14:39:56.062493Z","iopub.execute_input":"2024-12-19T14:39:56.062784Z","iopub.status.idle":"2024-12-19T14:39:56.067028Z","shell.execute_reply.started":"2024-12-19T14:39:56.062762Z","shell.execute_reply":"2024-12-19T14:39:56.066218Z"}},"outputs":[],"execution_count":77},{"cell_type":"markdown","source":"어플리케이션 통신","metadata":{}},{"cell_type":"code","source":"from pyngrok import ngrok\n\n# ngrok 인증 토큰 등록\nngrok.set_auth_token(\"2iLDfJFLUtVvODLsCKQghY5gqdg_42WA6QBqDa9BABji6QRae\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from flask import Flask, request, jsonify\nimport io\nimport requests\nfrom pyngrok import ngrok\nfrom transformers import pipeline\nfrom dateutil.parser import parse\nimport re\nimport torch\n\n# GPU 사용 가능 여부 확인\ndevice = 0 if torch.cuda.is_available() else -1\n\ngemini_api_key = \"AIzaSyCEtG0v1gxLCykmxscNwFat0rgeWb990NA\" \nmodel_path = \"/kaggle/working/output/checkpoint-500\"\ntokenizer_path = \"hyunwoongko/kobart\"\nmodel = BartForConditionalGeneration.from_pretrained(model_path).cuda()\ntokenizer = PreTrainedTokenizerFast.from_pretrained(tokenizer_path)\n# 학습된 모델로 제목 생성\nmax_length = 250\nmax_dec_length = 60\n\nner_model = pipeline(\n    \"token-classification\",\n    model=\"monologg/koelectra-small-finetuned-naver-ner\",\n    tokenizer=\"monologg/koelectra-small-finetuned-naver-ner\",\n    device=device)\n\napp = Flask(__name__)\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n    data = request.json\n    if 'image' not in data:\n        return jsonify({'error': 'No image URL provided'}), 400\n\n    image_url = data['image']\n    try:\n        # 이미지 URL에서 이미지를 다운로드합니다.\n        bucket_name, file_name = extract_bucket_and_filename(image_url)\n        # 버킷 가져오기\n        bucket = client.get_bucket(bucket_name)\n\n        # 블롭(파일) 가져오기\n        blob = bucket.blob(file_name)\n\n        # 블롭 URL에서 파일 다운로드\n        image_data = blob.download_as_bytes()\n\n        # 이미지 열기\n        img= Image.open(io.BytesIO(image_data)).convert('RGB')\n#         response = requests.get(image_url)\n#         response.raise_for_status()\n#         img = Image.open(io.BytesIO(response.content)).convert('RGB')\n    except requests.RequestException as e:\n        return jsonify({'error': f'Failed to download image: {str(e)}'}), 400\n    except Exception as e:\n        return jsonify({'error': f'Failed to open image: {str(e)}'}), 400\n\n    extracted_text = extract_text_from_image_google_vision(img) \n    generated_title = generate_title_from_text(model, tokenizer,extracted_text, max_length, max_dec_length)\n    dates,times = extract_datetime_entities(extracted_text)\n    date= get_earliest_date(dates)\n    time = get_earliest_time(times)\n    print(f\"결과 확인: {generated_title,date,time}\")\n\n    return jsonify({'schedule_title': generated_title, 'date': date, 'time': time})\nif __name__ == '__main__':\n    # ngrok을 사용하여 공개 URL 생성\n    public_url = ngrok.connect(5000)\n    print(f\"Public URL: {public_url}\")\n    app.run(host='0.0.0.0', port=5000)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}